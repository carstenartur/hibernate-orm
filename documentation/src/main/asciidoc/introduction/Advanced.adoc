[[advanced]]
== Advanced Topics

In the last chapter of this Introduction, we turn to some topics that don't really belong in an introduction.
Here we consider some problems, and solutions, that you're probably not going to run into immediately if you're new to Hibernate.
But we do want you to know _about_ them, so that when the time comes, you'll know what tool to reach for.

[[filters]]
=== Filters

_Filters_ are one of the nicest and under-usedest features of Hibernate, and we're quite proud of them.
A filter is a named, globally-defined, parameterized restriction on the data that is visible in a given session.

Examples of well-defined filters might include:

- a filter that restricts the data visible to a given user according to row-level permissions,
- a filter which hides data which has been soft-deleted,
- in a versioned database, a filter that displays versions which were current at a given instant in the past, or
- a filter that restricts to data associated with a certain geographical region.

A filter must be declared somewhere.
A package descriptor is as good a place as any:

[source,java]
----
@FilterDef(name = "ByRegion",
           parameters = @ParamDef(name = "region", type = String.class))
package org.hibernate.example;
----

This filter has one parameter.
Fancier filters might in principle have multiple parameters, though we admit this must be quite rare.

[IMPORTANT]
====
If you add annotations to a package descriptor, and you're using `Configuration` to configure Hibernate, make sure you call `Configuration.addPackage()` to let Hibernate know that the package descriptor is annotated.
====

_Typically_, but not necessarily, a `@FilterDef` specifies a default restriction:

[source,java]
----
@FilterDef(name = "ByRegion",
           parameters = @ParamDef(name = "region", type = String.class),
           defaultCondition = "region = :region")
package org.hibernate.example;
----

The restriction must contain a reference to the parameter of the filter, specified using the usual syntax for named parameters.

Any entity or collection which is affected by a filter must be annotated `@Filter`:

[source,java]
----
@Entity
@Filter(name = "ByRegion")
class User {

    @Id String username;

    String region;

    ...
}
----

If the `@Filter` annotation does not explicitly specify a restriction, the default restriction given by the `@FilterDef` will be applied to the entity.
But an entity is free to override the default condition.

[source,java]
----
@Entity
@Filter(name = "ByRegion", condition = "name = :region")
class Region {

    @Id String name;

    ...
}
----

Note that the restriction specified by the `condition` or `defaultCondition` is a native SQL expression.

By default, a new session comes with every filter disabled.
A filter may be explicitly enabled in a given session by calling `enableFilter()` and assigning arguments to the parameters of the filter.
You should do this right at the _start_ of the session.

[source,java]
----
sessionFactory.inTransaction(session -> {
    session.enableFilter("ByRegion")
        .setParameter("region", "es")
        .validate();

    ...
});
----

Now, any queries executed within the session will have the filter restriction applied.
Collections annotated `@Filter` will also have their members correctly filtered.

[CAUTION]
====
On the other hand, filters are not applied to `@ManyToOne` associations, nor to `find()`.
This is completely by design and is not in any way a bug.
====

More than one filter may be enabled in a given session.

A closely-related problem is multi-tenancy.

[[multitenancy]]
=== Multi-tenancy

A _multi-tenant_ database is one where the data is segregated by _tenant_.
We don't need to actually define what a "tenant" really represents here; all we care about at this level of abstraction is that each tenant may be distinguished by a unique identifier.
And that there's a well-defined _current tenant_ in each session.

We may specify the current tenant when we open a session:

[source,java]
----
var session =
        sessionFactory.withOptions()
            .tenantIdentifier(tenantId)
            .openSession();
----

Or, when using JPA-standard APIs:

[source,java]
----
var entityManager =
        entityManagerFactory.createEntityManager(Map.of(HibernateHints.HINT_TENANT_ID, tenantId));
----

However, since we often don't have this level of control over creation of the session, it's more common to supply an implementation of `CurrentTenantIdentifierResolver` to Hibernate.

There are three common ways to implement multi-tenancy:

1. each tenant has its own database,
2. each tenant has its own schema, or
3. tenants share tables in a single schema, and rows are tagged with the tenant id.

From the point of view of Hibernate, there's little difference between the first two options.
Hibernate will need to obtain a JDBC connection with permissions on the database and schema owned by the current tenant.

Therefore, we must implement a `MultiTenantConnectionProvider` which takes on this responsibility:

- from time to time, Hibernate will ask for a connection, passing the id of the current tenant, and then we must create an appropriate connection or obtain one from a pool, and return it to Hibernate, and
- later, Hibernate will release the connection and ask us to destroy it or return it to the appropriate pool.

[TIP]
====
Check out `DataSourceBasedMultiTenantConnectionProviderImpl` for inspiration.
====

The third option is quite different.
In this case we don't need a `MultiTenantConnectionProvider`, but we will need a dedicated column holding the tenant id mapped by each of our entities.

[source,java]
----
@Entity
class Account {
    @Id String id;
    @TenantId String tenantId;
    
    ...
}
----

The `@TenantId` annotation is used to indicate an attribute of an entity which holds the tenant id.
Within a given session, our data is automatically filtered so that only rows tagged with the tenant id of the current tenant are visible in that session.

[CAUTION]
====
Native SQL queries are _not_ automatically filtered by tenant id; you'll have to do that part yourself.
====

.Multi-tenancy configuration
[cols="35,~"]
|===
| Configuration property name           | Purpose

| `hibernate.tenant_identifier_resolver`  | Specifies the `CurrentTenantIdentifierResolver`
| `hibernate.multi_tenant_connection_provider`  | Specifies the `MultiTenantConnectionProvider`
|===

[TIP]
====
If you only need to filter rows by a static condition with no parameters, `@SQLRestriction` is a much simpler way to do that.
====

[[custom-sql]]
=== Using custom-written SQL

We've already discussed how to run <<native-queries,queries written in SQL>>, but occasionally that's not enough.
Sometimes—but much less often than you might expect—we would like to customize the SQL used by Hibernate to perform basic CRUD operations for an entity or collection.

For this we can use `@SQLInsert` and friends:

[source,java]
----
@Entity
@SQLInsert(sql = "insert into person (name, id, valid) values (?, ?, true)", check = COUNT)
@SQLUpdate(sql = "update person set name = ? where id = ?")
@SQLDelete(sql = "update person set valid = false where id = ?")
@SQLSelect(sql = "select id, name from person where id = ? and valid = true")
public static class Person { ... }
----

[TIP]
====
If the custom SQL should be executed via a `CallableStatement`, just specify `callable=true`.
====

Any SQL statement specified by one of these annotations must have exactly the number of JDBC parameters that Hibernate expects, that is, one for each column mapped by the entity, in the exact order Hibernate expects. In particular, the primary key columns must come last.

However, the `@Column` annotation does lend some flexibility here:

- if a column should not be written as part of the custom `insert` statement, and has no corresponding JDBC parameter in the custom SQL, map it `@Column(insertable=false)`, or
- if a column should not be written as part of the custom `update` statement, and has no corresponding JDBC parameter in the custom SQL, map it `@Column(updatable=false)`.

[TIP]
====
If you need custom SQL, but are targeting multiple dialects of SQL, you can use the annotations defined in `DialectOverrides`.
For example, this annotation lets us override the custom `insert` statement just for PostgreSQL:

[source,java]
----
@DialectOverride.SQLInsert(dialect = PostgreSQLDialect.class,
    override = @SQLInsert(sql="insert into person (name,id) values (?,gen_random_uuid())"))
----
It's even possible to override the custom SQL for specific _versions_ of a database.
====

Sometimes a custom `insert` or `update` statement assigns a value to a mapped column which is calculated when the statement is executed on the database.
For example, the value might be obtained by calling a SQL function:

[source,java]
----
@SQLInsert(sql = "insert into person (name, id) values (?, gen_random_uuid())")
----

But the entity instance which represents the row being inserted or updated won't be automatically populated with that value.
And so our persistence context loses synchronization with the database.
In situations like this, we may use the `@Generated` annotation to tell Hibernate to reread the state of the entity after each `insert` or `update`.

[[database-generated-columns]]
=== Handling database-generated columns

Sometimes, a column value is assigned or mutated by events that happen in the database, and aren't visible to Hibernate.
For example:

- a table might have a column value populated by a trigger,
- a mapped column might have a default value defined in DDL, or
- a custom SQL `insert` or `update` statement might assign a value to a mapped column, as we saw in the previous subsection.

One way to deal with this situation is to explicitly call `refresh()` at appropriate moments, forcing the session to reread the state of the entity.
But this is annoying.

The `@Generated` annotation relieves us of the burden of explicitly calling `refresh()`.
It specifies that the value of the annotated entity attribute is generated by the database, and that the generated value should be automatically retrieved using a SQL `returning` clause, or separate `select` after it is generated.

A useful example is the following mapping:

[source,java]
----
@Entity
class Entity {
    @Generated @Id
    @ColumnDefault("gen_random_uuid()")
    UUID id;
}
----

The generated DDL is:

[source,sql]
----
create table Entity (
    id uuid default gen_random_uuid() not null,
    primary key (uuid)
)
----

So here the value of `id` is defined by the column default clause, by calling the PostgreSQL function `gen_random_uuid()`.

When a column value is generated during updates, use `@Generated(event=UPDATE)`.
When a value is generated by both inserts _and_ updates, use `@Generated(event={INSERT,UPDATE})`.

[TIP]
====
For columns which should be generated using a SQL `generated always as` clause, prefer the `@GeneratedColumn` annotation, so that Hibernate automatically generates the correct DDL.
====

Actually, the `@Generated` and `@GeneratedColumn` annotations are defined in terms of a more generic and user-extensible framework for handling attribute values generated in Java, or by the database.

[[user-defined-generators]]
=== User-defined generators

JPA doesn't define a standard way to extend the set of id generation strategies, but Hibernate does:

- the `Generator` hierarchy of interfaces in the package `org.hibernate.generator` lets you define new generators, and
- the `@IdGeneratorType` meta-annotation from the package `org.hibernate.annotations` lets you write an annotation which associates a `Generator` type with identifier attributes.

Furthermore, the `@ValueGenerationType` meta-annotation lets you write an annotation which associates a `Generator` type with a non-`@Id` attribute.

[NOTE]
// .The older APIs are still available in Hibernate 6
====
These APIs are new in Hibernate 6, and supersede the classic `IdentifierGenerator` interface and `@GenericGenerator` annotation from older versions of Hibernate.
However, the older APIs are still available and custom ``IdentifierGenerator``s written for older versions of Hibernate continue to work in Hibernate 6.
====

Hibernate has a range of built-in generators which are defined in terms of this new framework.

.Built-in generators
[cols="20,25,~"]
|===
| Annotation | Implementation | Purpose

| `@Generated` | `GeneratedGeneration` | Generically handles database-generated values
| `@GeneratedColumn` | `GeneratedAlwaysGeneration` | Handles values generated using `generated always`
| `@CurrentTimestamp` | `CurrentTimestampGeneration` | Generic support for database or in-memory generation of creation or update timestamps
| `@CreationTimestamp` | `CurrentTimestampGeneration` | A timestamp generated when an entity is first made persistent
| `@UpdateTimestamp` | `CurrentTimestampGeneration` | A timestamp generated when an entity is made persistent, and regenerated every time the entity is modified
| `@UuidGenerator` | `UuidGenerator` | A more flexible generator for RFC 4122 UUIDs
|===

Furthermore, support for JPA's standard id generation strategies is also defined in terms of this framework.

As an example, let's look at how `@UuidGenerator` is defined:

[source,java]
----
@IdGeneratorType(org.hibernate.id.uuid.UuidGenerator.class)
@ValueGenerationType(generatedBy = org.hibernate.id.uuid.UuidGenerator.class)
@Retention(RUNTIME)
@Target({ FIELD, METHOD })
public @interface UuidGenerator { ... }
----

`@UuidGenerator` is meta-annotated both `@IdGeneratorType` and `@ValueGenerationType` because it may be used to generate both ids and values of regular attributes.
Either way, this `Generator` class does the hard work:

[source,java]
----
public class UuidGenerator
        // this generator produced values before SQL is executed
        implements BeforeExecutionGenerator {
    
    // constructors accept an instance of the @UuidGenerator
    // annotation, allowing the generator to be "configured"

    // called to create an id generator
    public UuidGenerator(
            org.hibernate.annotations.UuidGenerator config,
            Member idMember,
            CustomIdGeneratorCreationContext creationContext) {
        this(config, idMember);
    }

    // called to create a generator for a regular attribute
    public UuidGenerator(
            org.hibernate.annotations.UuidGenerator config,
            Member member,
            GeneratorCreationContext creationContext) {
        this(config, idMember);
    }
    
    ...

    @Override
    public EnumSet<EventType> getEventTypes() {
        // UUIDs are only assigned on insert, and never regenerated
        return INSERT_ONLY;
    }

    @Override
    public Object generate(SharedSessionContractImplementor session, Object owner, Object currentValue, EventType eventType) {
        // actually generate a UUID and transform it to the required type
        return valueTransformer.transform( generator.generateUuid( session ) );
    }
}
----

You can find out more about custom generators from the Javadoc for `@IdGeneratorType` and for `org.hibernate.generator`.


[[naming-strategies]]
=== Naming strategies

When working with a pre-existing relational schema, it's usual to find that the column and table naming conventions used in the schema don't match Java's naming conventions.

Of course, the `@Table` and `@Column` annotations let us explicitly specify a mapped table or column name.
But we would prefer to avoid scattering these annotations across our whole domain model.

Therefore, Hibernate lets us define a mapping between Java naming conventions, and the naming conventions of the relational schema.
Such a mapping is called a _naming strategy_.

First, we need to understand how Hibernate assigns and processes names.

- _Logical naming_ is the process of applying naming rules to determine the _logical names_ of objects which were not explicitly assigned names in the O/R mapping.
  That is, when there's no `@Table` or `@Column` annotation.
- _Physical naming_ is the process of applying additional rules to transform a logical name into an actual "physical" name that will be used in the database.
  For example, the rules might include things like using standardized abbreviations, or trimming the length of identifiers.

Thus, there's two flavors of naming strategy, with slightly different responsibilities.
Hibernate comes with default implementations of these interfaces:


|===
| Flavor | Default implementation

| An `ImplicitNamingStrategy` is responsible for assigning a logical name when none is specified by an annotation
| A default strategy which implements the rules defined by JPA
| A `PhysicalNamingStrategy` is responsible for transforming a logical name and producing the name used in the database
| A trivial implementation which does no processing
|===

[TIP]
====
We happen to not much like the naming rules defined by JPA, which specify that mixed case and camel case identifiers should be concatenated using underscores.
We bet you could easily come up with a much better `ImplicitNamingStrategy` than that!
(Hint: it should always produce legit mixed case identifiers.)
====
[TIP]
====
A popular `PhysicalNamingStrategy` produces snake case identifiers.
====

Custom naming strategies may be enabled using the configuration properties we already mentioned without much explanation back in <<minimizing>>.

.Naming strategy configuration
[cols="35,~"]
|===
| Configuration property name           | Purpose

| `hibernate.implicit_naming_strategy`  | Specifies the `ImplicitNamingStrategy`
| `hibernate.physical_naming_strategy`  | Specifies the `PhysicalNamingStrategy`
|===

[[spatial]]
=== Spatial datatypes

:ogc: https://www.ogc.org
:geolatte: https://github.com/GeoLatte/geolatte-geom

Hibernate Spatial augments the <<basic-attributes,built-in basic types>> with a set of Java mappings for {ogc}[OGC] spatial types.

- {geolatte}[Geolatte-geom] defines a set of Java types implementing the OGC spatial types, and codecs for translating to and from database-native spatial datatypes.
- Hibernate Spatial itself supplies integration with Hibernate.

To use Hibernate Spatial, we must add it as a dependency, as described in <<optional-dependencies>>.

Then we may immediately use Geolatte-geom and JTS types in our entities.
No special annotations are needed:

[source,java]
----
import org.locationtech.jts.geom.Point;
import jakarta.persistence.*;

@Entity
class Event {
    Event() {}

    Event(String name, Point location) {
        this.name = name;
        this.location = location;
    }

    @Id @GeneratedValue
    Long id;

    String name;

    Point location;

}
----

The generated DDL uses `geometry` as the type of the column mapped by `location`:

[source,sql]
----
create table Event (
    id bigint not null,
    location geometry,
    name varchar(255),
    primary key (id)
)
----

Hibernate Spatial lets us work with spatial types just as we would with any of the built-in basic attribute types.

[source,java]
----
var geometryFactory = new GeometryFactory();

...

Point point = geometryFactory.createPoint(new Coordinate(10, 5));
session.persist(new Event("Hibernate ORM presentation", point));
----

But what makes this powerful is that we may write some very fancy queries involving functions of spatial types:

[source,java]
----
Polygon triangle =
        geometryFactory.createPolygon(
                new Coordinate[] {
                        new Coordinate(9, 4),
                        new Coordinate(11, 4),
                        new Coordinate(11, 20),
                        new Coordinate(9, 4)
                }
        );
Point event =
        session.createQuery("select location from Event where within(location, :zone) = true", Point.class)
                .setParameter("zone", triangle)
                .getSingleResult();
----

:matrix: {userGuideBase}#spatial-configuration-dialect-features

Here, `within()` is one of the functions for testing spatial relations defined by the OpenGIS specification.
Other such functions include `touches()`, `intersects()`, `distance()`, `boundary()`, etc.
Not every spatial relation function is supported on every database.
A matrix of support for spatial relation functions may be found in the {matrix}[User Guide].

[TIP]
====
If you want to play with spatial functions on H2, run the following code first:

[source,java]
----
sessionFactory.inTransaction(session -> {
    session.doWork(connection -> {
        try (var statement = connection.createStatement()) {
            statement.execute("create alias if not exists h2gis_spatial for \"org.h2gis.functions.factory.H2GISFunctions.load\"");
            statement.execute("call h2gis_spatial()");
        }
    });
} );
----
====

[[any]]
=== Any mappings

An `@Any` mapping is a sort of polymorphic many-to-one association where the target entity types are not related by the usual entity inheritance.
The target type is distinguished using a discriminator value stored on the _referring_ side of the relationship.

This is quite different to <<entity-inheritance,discriminated inheritance>> where the discriminator is held in the tables mapped by the referenced entity hierarchy.

For example, consider an `Order` entity containing `Payment` information, where a `Payment` might be a `CashPayment` or a `CreditCardPayment`:

[source,java]
----
interface Payment { ... }

@Entity
class CashPayment { ... }

@Entity
class CreditCardPayment { ... }
----

In this example, `Payment` is not be declared as an entity type, and is not annotated `@Entity`. It might even be an interface, or at most just a mapped superclass, of `CashPayment` and `CreditCardPayment`. So in terms of the object/relational mappings, `CashPayment` and `CreditCardPayment` would not be considered to participate in the same entity inheritance hierarchy.

On the other hand, `CashPayment` and `CreditCardPayment` do have the same identifier type.
This is important.


An `@Any` mapping would store the discriminator value identifying the concrete type of `Payment` along with the state of the associated `Order`, instead of storing it in the table mapped by `Payment`.

[source,java]
----
@Entity
class Order {
    ...

    @Any
    @JoinColumn(name="payment_id") // the foreign key column
    @Column(name="payment_type")   // the discriminator column
    // map from discriminator values to target entity types
    @AnyDiscriminatorValue(discriminator="CASH", entity=CashPayment.class)
    @AnyDiscriminatorValue(discriminator="CREDIT", entity=CreditCardPayment.class)
    Payment payment;

    ...
}
----

It's reasonable to think of the "foreign key" in an `@Any` mapping as a composite value made up of the foreign key and discriminator taken together. Note, however, that this composite foreign key is only conceptual and cannot be declared as a physical constraint on the relational database table.

There are a number of annotations which are useful to express this sort of complicated and unnatural mapping:

.Annotations for `@Any` mappings
|===
| Annotations | Purpose

| `@AnyDiscriminator`, `@JdbcType`, or `@JdbcTypeCode` | Specify the type of the discriminator
| `@AnyDiscriminatorValue` | Specifies how discriminator values map to entity types
| `@Column` or `@Formula` | Specify the column or formula in which the discriminator value is stored
| `@AnyKeyJavaType`, `@AnyKeyJavaClass`, `@AnyKeyJdbcType`, or `@AnyKeyJdbcTypeCode` | Specify the type of the foreign key (that is, of the ids of the target entities)
| `@JoinColumn` | Specifies the foreign key column
|===

Of course, `@Any` mappings are disfavored, except in extremely special cases, since it's much more difficult to enforce referential integrity at the database level.

[[bytecode-enhancer]]
=== Using the bytecode enhancer

:enhancer: {userGuideBase}#BytecodeEnhancement

Hibernate's {enhancer}[bytecode enhancer] enables the following features:

- _attribute-level lazy fetching_ for basic attributes annotated `@Basic(fetch=LAZY)` and for lazy non-polymorphic associations,
- _interception-based_—instead of the usual _snapshot-based_—detection of modifications.

To use the bytecode enhancer, we must add the Hibernate plugin to our gradle build:

[source,groovy]
----
plugins {
    id "org.hibernate.orm" version "6.2.2.Final"
}

hibernate { enhancement }
----

// [discrete]
// ==== Attribute-level lazy fetching

Consider this field:

[source,java]
----
@Entity
class Book {
    ...

    @Basic(optional = false, fetch = LAZY)
    @Column(length = LONG32)
    String fullText;
    
    ...
}
----

The `fullText` field maps to a `clob` or `text` column, depending on the SQL dialect.
Since it's expensive to retrieve the full book-length text, we've mapped the field `fetch=LAZY`, telling Hibernate not to read the field until it's actually used.

- _Without_ the bytecode enhancer, this instruction is ignored, and the field is always fetched immediately, as part of the initial `select` that retrieves the `Book` entity.
- _With_ bytecode enhancement, Hibernate is able to detect access to the field, and lazy fetching is possible.

[TIP]
====
By default, Hibernate fetches all lazy fields of a given entity at once, in a single `select`, when any one of them is accessed.
Using the `@LazyGroup` annotation, it's possible to assign fields to distinct "fetch groups", so that different lazy fields may be fetched independently.
====

Similarly, interception lets us implement lazy fetching for non-polymorphic associations without the need for a separate proxy object.
However, if an association is polymorphic, that is, if the target entity type has subclasses, then a proxy is still required.

// [discrete]
// ==== Interception-based change detection

Interception-based change detection is a nice performance optimization with a slight cost in terms of correctness.

- _Without_ the bytecode enhancer, Hibernate keeps a snapshot of the state of each entity after reading from or writing to the database.
When the session flushes, the snapshot state is compared to the current state of the entity to determine if the entity has been modified.
Maintaining these snapshots does have an impact on performance.
- _With_ bytecode enhancement, we may avoid this cost by intercepting writes to the field and recording these modifications as they happen.

[CAUTION]
====
Interception-based change detection is less accurate than snapshot-based dirty checking.
For example, consider this attribute:

[source,java]
byte[] image;

Interception is able to detect writes to the `image` field, that is, replacement of the whole array.
It's not able to detect modifications made directly to the _elements_ of the array, and so such modifications may be lost.
====
